{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf65206-6a6f-493a-a745-b1231fd74742",
   "metadata": {},
   "source": [
    "# <span style=\"color: #3498db; font-size: 36px; font-family: 'Arial', sans-serif; font-weight: bold; display: block; text-align: center; position: absolute; top: 15%; left: 15%; transform: translate(-25%, -25%); background-color: #f2f2f2; padding: 10px; border-radius: 10px;\">Next Word Prediction with LSTM Neural Networks</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133328e-61c8-4656-a405-52a94eb95c7c",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #3498db;\">Introduction</h2>\n",
    "\n",
    "In this project, we explore a fascinating task in the realm of **Natural Language Processing** (NLP): Next Word Prediction. The goal is to predict the next word in a sentence based on the context provided by the preceding words. This task has numerous practical applications, such as improving text input systems and generating coherent and appropriate sentences.<br>\n",
    "\n",
    "To achieve this, we'll use the power of **Long Short-Term Memory** (LSTM) networks, a type of **recurrent neural network** (RNN) that excels at learning and remembering long-term dependencies in sequences, which makes it perfect for working with text. To do so, I'll train our model on a large dataset, and it will learn the patterns and structure of language, enabling it to predict the next word in a given sequence with remarkable accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c9f86-2ac6-41e6-a38b-d1fe4e2a3ef0",
   "metadata": {},
   "source": [
    "![Image](NextwordPredict.png\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16239b6-0d02-46c8-b3c3-9c6f3f0724f6",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Importing Libraries for Text Processing and LSTM Modeling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dbc2f80-dded-49fe-8018-284125238f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202d67f-1404-4e2b-8a14-f02550919a68",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Reading And Cleaning Text Data </h3>\n",
    "In this project, we'll be using the text of Sherlock Holmes as our dataset. By processing and cleaning the text, we can prepare it for tasks such as next-word prediction and text generation, providing a foundation for our model to learn from the structure and patterns in the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a392ad13-ed71-4123-9509-76313a740676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ADVENTURES OF SHERLOCK HOLMES\n",
      "Arthur Conan Doyle\n",
      "Table of contents\n",
      "A Scandal in Bohemia\n",
      "The Red-Headed League\n",
      "A Case of Identity\n",
      "The Boscombe Valley Mystery\n",
      "The Five Orange Pips\n",
      "The Man with the Twisted Lip\n",
      "The Adventure of the Blue Carbuncle\n",
      "The Adventure of the Speckled Band\n",
      "The Adventure of the Engineer's Thumb\n",
      "The Adventure of the Noble Bachelor\n",
      "The Adventure of the Beryl Coronet\n",
      "The Adventure of the Copper Beeches\n",
      "A SCANDAL IN BOHEMIA\n",
      "Table of contents\n",
      "Chapter 1\n",
      "Chapter 2\n",
      "Chapter 3\n",
      "CHAP\n"
     ]
    }
   ],
   "source": [
    "# Reading the data and cleaning it.\n",
    "\n",
    "with open('sherlock-holm.es_stories_plain-text_advs.txt', 'r', encoding='utf-8') as text_file:\n",
    "    raw_text = text_file.read()\n",
    "cleaned_text = \"\\n\".join([line.strip() for line in raw_text.split('\\n') if line.strip() != \"\"])\n",
    "print(cleaned_text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f686064-8d0e-452f-b2b3-aa23562f9e30",
   "metadata": {},
   "source": [
    "The output shows that the data is well-organized, with clearly split lines and structured text. Each line represents distinct content, such as the title, author, table of contents, and story sections, indicating that the cleaning process was successful. This structure makes the data ready for tokenization and sequence generation in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169f418-f396-4b41-8818-91d213fda0bd",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Tokenization </h3>\n",
    "Here, we use a tokenizer to convert the text into numerical values, essentially creating a unique index for each word. From the output, we can see the total vocabulary size and a sample of the first 10 word-to-index mappings. This step is super important because it helps us translate the text into something the model can actually understand and work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b19a8fa4-f229-482f-a1b9-adfd10464cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 8200\n",
      "[('the', 1), ('and', 2), ('i', 3), ('to', 4), ('of', 5), ('a', 6), ('in', 7), ('that', 8), ('it', 9), ('he', 10)]\n"
     ]
    }
   ],
   "source": [
    "# Creating a tokenizer based on our cleaned_text.\n",
    "text_tokenizer = Tokenizer()\n",
    "text_tokenizer.fit_on_texts([cleaned_text])\n",
    "total_vocab = len(text_tokenizer.word_index) + 1\n",
    "print(f\"Total vocabulary size: {total_vocab}\")\n",
    "print(list(text_tokenizer.word_index.items())[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec3306-a045-45cd-a900-86855a0c9668",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Generating n-gram Sequences </h3>\n",
    "Here, we generate n-gram sequences from the cleaned text, which are chunks of text containing sequences of words. Each sequence includes an increasing number of words, one at a time, making it useful for training the model to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68168038-7105-4422-ac66-306b7336db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1561], [1, 1561, 5], [1, 1561, 5, 129], [1, 1561, 5, 129, 34], [647, 4498]]\n",
      "Total number of sequences generated: 96314\n"
     ]
    }
   ],
   "source": [
    "# Generate n-gram sequences for training\n",
    "sequence_data = []\n",
    "for sentence in cleaned_text.split('\\n'):\n",
    "    token_sequence = text_tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for j in range(1, len(token_sequence)):\n",
    "        n_gram_seq = token_sequence[:j+1]\n",
    "        sequence_data.append(n_gram_seq)\n",
    "print(sequence_data[:5])\n",
    "print(f\"Total number of sequences generated: {len(sequence_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2cf8b-993e-44ad-a98e-20d7f5b37686",
   "metadata": {},
   "source": [
    "From the output, we can see the first 5 sequences and the total number of sequences generated. This step is crucial for preparing the data for our text generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1416e0aa-34e2-4b9e-b2b1-8ca7b3f52141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 18\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1 1561]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1 1561    5]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1 1561    5  129]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "  1561    5  129   34]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0  647 4498]]\n"
     ]
    }
   ],
   "source": [
    "# Padding our sequences to the same length\n",
    "max_seq_length = max([len(sequence) for sequence in sequence_data])\n",
    "print(f\"Maximum sequence length: {max_seq_length}\")\n",
    "padded_sequences = pad_sequences(sequence_data, maxlen=max_seq_length, padding='pre')\n",
    "print(padded_sequences[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf71f6-d7db-4d31-a679-2a851f71e762",
   "metadata": {},
   "source": [
    "In this step, we pad all the sequences to ensure they have the same length. The maximum sequence length is calculated, and shorter sequences are padded with zeros at the beginning to match this length. This standardization is essential because models require input of uniform size. From the output, we can see the maximum sequence length and the first 5 padded sequences, all of which are now the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1815a08-f53d-4974-afb3-738333891544",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Data Preparation for Model Training </h3>\n",
    "Here, we split the padded sequences into features (X_features) and target labels (y_labels). The features include all columns except the last one, while the last column is used as the target label. We then perform one-hot encoding on the target labels to convert them into a format suitable for multi-class classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a037881-5e6a-410d-8513-c00d0561a038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_features: (96314, 17)\n",
      "Shape of y_labels: (96314, 8200)\n"
     ]
    }
   ],
   "source": [
    "X_features = padded_sequences[:, :-1]  # All columns except the last one\n",
    "y_labels = padded_sequences[:, -1]     # The last column as the target\n",
    "\n",
    "# Perform one-hot encoding on the target labels\n",
    "y_labels = tf.keras.utils.to_categorical(y_labels, num_classes=total_vocab)\n",
    "print(f\"Shape of X_features: {X_features.shape}\")  # (number of sequences, max sequence length - 1)\n",
    "print(f\"Shape of y_labels: {y_labels.shape}\")      # (number of sequences, vocabulary size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f08c7-17d1-4285-a337-9fe66a0eeabd",
   "metadata": {},
   "source": [
    "The output shows the shapes of X_features and y_labels after splitting the padded sequences. X_features has a shape of (96,314, 17), meaning there are 96,314 sequences, each of length 17 (excluding the target word). y_labels has a shape of (96,314, 8,200), where 8,200 represents the total vocabulary size, with each label one-hot encoded. This confirms that the data is correctly prepared for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830fae6-e479-4f20-b2d5-77c23b7fd5ed",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Defining our LSTM-Based Sequential Model </h3>\n",
    "Here, we define our sequential model for text generation. The model consists of three main layers:\n",
    "\n",
    "- An Embedding layer that transforms words into dense vectors of size 100.\n",
    "- An LSTM layer with 150 units, which captures the sequential nature of the data.\n",
    "- A Dense layer with total_vocab units and a softmax activation, which predicts the probability distribution of the next word in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d429eca-48e4-4ea2-8473-81df050c55d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">820,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8200</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,238,200</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m820,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8200\u001b[0m)           │     \u001b[38;5;34m1,238,200\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,208,800</span> (8.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,208,800\u001b[0m (8.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,208,800</span> (8.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,208,800\u001b[0m (8.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# We define our sequential model with a LSTM Layer of 150 units\n",
    "\n",
    "text_generation_model = Sequential([\n",
    "    Input(shape=(max_seq_length - 1,)),  \n",
    "    Embedding(input_dim=total_vocab, output_dim=100),\n",
    "    LSTM(150),  # LSTM layer with 150 units\n",
    "    Dense(total_vocab, activation='softmax')  \n",
    "    \n",
    "text_generation_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(text_generation_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0194aa0-845f-4372-9714-761d222b64f1",
   "metadata": {},
   "source": [
    "The summary output shows the architecture of our model:\n",
    "\n",
    "- **The Embedding layer** outputs vectors of size (17, 100) for each sequence (17 being the input sequence length).\n",
    "- **The LSTM layer** outputs vectors of size (150) for each input sequence.\n",
    "- **The Dense layer** predicts the next word with a vocabulary size of 8,200.\n",
    "Additionally, the total number of trainable parameters is 2,208,800, indicating the complexity of the model. This well-structured architecture is now ready for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04991d8-86af-4d0d-9ea0-cde86004a5a7",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Model Training</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6be4a-f674-4489-85cc-dc71366da7aa",
   "metadata": {},
   "source": [
    "Now that the model architecture is defined, we move on to training the model. We compile the model using:\n",
    "\n",
    "- **Categorical_crossentropy** as the loss function, which is ideal for multi-class classification tasks.\n",
    "- **Adam** as the optimizer for efficient and adaptive learning.\n",
    "- **Accuracy** as the evaluation metric to track how well the model is performing during training.\n",
    "\n",
    "The model is trained on X_features and y_labels for 100 epochs, during which it learns to predict the next word in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0378e8cc-3ff8-495f-b9d4-ce639697eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.0608 - loss: 6.5504\n",
      "Epoch 2/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.1200 - loss: 5.5480\n",
      "Epoch 3/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.1487 - loss: 5.1128\n",
      "Epoch 4/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.1644 - loss: 4.7645\n",
      "Epoch 5/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.1861 - loss: 4.4462\n",
      "Epoch 6/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.2083 - loss: 4.1473\n",
      "Epoch 7/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.2383 - loss: 3.8565\n",
      "Epoch 8/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.2714 - loss: 3.5931\n",
      "Epoch 9/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3034 - loss: 3.3509\n",
      "Epoch 10/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.3405 - loss: 3.1208\n",
      "Epoch 11/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3771 - loss: 2.9125\n",
      "Epoch 12/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.4124 - loss: 2.7260\n",
      "Epoch 13/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4462 - loss: 2.5389\n",
      "Epoch 14/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.4809 - loss: 2.3743\n",
      "Epoch 15/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.5066 - loss: 2.2390\n",
      "Epoch 16/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.5392 - loss: 2.0882\n",
      "Epoch 17/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.5624 - loss: 1.9631\n",
      "Epoch 18/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.5887 - loss: 1.8487\n",
      "Epoch 19/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.6146 - loss: 1.7359\n",
      "Epoch 20/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.6337 - loss: 1.6436\n",
      "Epoch 21/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.6554 - loss: 1.5435\n",
      "Epoch 22/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.6718 - loss: 1.4732\n",
      "Epoch 23/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.6855 - loss: 1.3929\n",
      "Epoch 24/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.7062 - loss: 1.3217\n",
      "Epoch 25/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.7163 - loss: 1.2675\n",
      "Epoch 26/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.7308 - loss: 1.2031\n",
      "Epoch 27/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.7438 - loss: 1.1536\n",
      "Epoch 28/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.7519 - loss: 1.1112\n",
      "Epoch 29/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.7606 - loss: 1.0642\n",
      "Epoch 30/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 16ms/step - accuracy: 0.7695 - loss: 1.0153\n",
      "Epoch 31/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.7793 - loss: 0.9779\n",
      "Epoch 32/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.7874 - loss: 0.9418\n",
      "Epoch 33/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.7969 - loss: 0.8985\n",
      "Epoch 34/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.8001 - loss: 0.8794\n",
      "Epoch 35/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8074 - loss: 0.8488\n",
      "Epoch 36/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8125 - loss: 0.8297\n",
      "Epoch 37/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8176 - loss: 0.8012\n",
      "Epoch 38/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - accuracy: 0.8198 - loss: 0.7904\n",
      "Epoch 39/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8244 - loss: 0.7644\n",
      "Epoch 40/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - accuracy: 0.8311 - loss: 0.7390\n",
      "Epoch 41/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8307 - loss: 0.7289\n",
      "Epoch 42/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 18ms/step - accuracy: 0.8384 - loss: 0.7054\n",
      "Epoch 43/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8404 - loss: 0.6985\n",
      "Epoch 44/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8427 - loss: 0.6846\n",
      "Epoch 45/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8461 - loss: 0.6678\n",
      "Epoch 46/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.8465 - loss: 0.6565\n",
      "Epoch 47/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8502 - loss: 0.6385\n",
      "Epoch 48/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8513 - loss: 0.6345\n",
      "Epoch 49/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8556 - loss: 0.6183\n",
      "Epoch 50/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8554 - loss: 0.6138\n",
      "Epoch 51/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8558 - loss: 0.6091\n",
      "Epoch 52/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8589 - loss: 0.5967\n",
      "Epoch 53/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - accuracy: 0.8573 - loss: 0.5977\n",
      "Epoch 54/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8599 - loss: 0.5875\n",
      "Epoch 55/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.8621 - loss: 0.5754\n",
      "Epoch 56/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8618 - loss: 0.5739\n",
      "Epoch 57/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8612 - loss: 0.5710\n",
      "Epoch 58/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8647 - loss: 0.5564\n",
      "Epoch 59/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8655 - loss: 0.5526\n",
      "Epoch 60/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8638 - loss: 0.5528\n",
      "Epoch 61/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8664 - loss: 0.5486\n",
      "Epoch 62/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 19ms/step - accuracy: 0.8669 - loss: 0.5434\n",
      "Epoch 63/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - accuracy: 0.8660 - loss: 0.5431\n",
      "Epoch 64/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - accuracy: 0.8700 - loss: 0.5316\n",
      "Epoch 65/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8668 - loss: 0.5356\n",
      "Epoch 66/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8677 - loss: 0.5314\n",
      "Epoch 67/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8712 - loss: 0.5208\n",
      "Epoch 68/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8693 - loss: 0.5262\n",
      "Epoch 69/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8694 - loss: 0.5195\n",
      "Epoch 70/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.8703 - loss: 0.5167\n",
      "Epoch 71/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8700 - loss: 0.5175\n",
      "Epoch 72/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8691 - loss: 0.5221\n",
      "Epoch 73/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8730 - loss: 0.5051\n",
      "Epoch 74/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - accuracy: 0.8694 - loss: 0.5151\n",
      "Epoch 75/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 19ms/step - accuracy: 0.8730 - loss: 0.5054\n",
      "Epoch 76/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8718 - loss: 0.5063\n",
      "Epoch 77/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8716 - loss: 0.5065\n",
      "Epoch 78/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 19ms/step - accuracy: 0.8747 - loss: 0.4983\n",
      "Epoch 79/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - accuracy: 0.8721 - loss: 0.5010\n",
      "Epoch 80/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8712 - loss: 0.5057\n",
      "Epoch 81/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.8715 - loss: 0.5046\n",
      "Epoch 82/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8747 - loss: 0.4928\n",
      "Epoch 83/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 19ms/step - accuracy: 0.8734 - loss: 0.4967\n",
      "Epoch 84/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - accuracy: 0.8759 - loss: 0.4847\n",
      "Epoch 85/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8759 - loss: 0.4865\n",
      "Epoch 86/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8725 - loss: 0.4984\n",
      "Epoch 87/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8741 - loss: 0.4869\n",
      "Epoch 88/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - accuracy: 0.8770 - loss: 0.4846\n",
      "Epoch 89/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8747 - loss: 0.4858\n",
      "Epoch 90/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8716 - loss: 0.4956\n",
      "Epoch 91/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8766 - loss: 0.4804\n",
      "Epoch 92/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8751 - loss: 0.4780\n",
      "Epoch 93/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.8733 - loss: 0.4850\n",
      "Epoch 94/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8730 - loss: 0.4848\n",
      "Epoch 95/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 18ms/step - accuracy: 0.8759 - loss: 0.4824\n",
      "Epoch 96/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.8743 - loss: 0.4812\n",
      "Epoch 97/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8770 - loss: 0.4747\n",
      "Epoch 98/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - accuracy: 0.8731 - loss: 0.4846\n",
      "Epoch 99/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.8766 - loss: 0.4707\n",
      "Epoch 100/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - accuracy: 0.8754 - loss: 0.4756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2899b15a0f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "text_generation_model.fit(X_features, y_labels, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1038545-6b05-4aa0-89ac-8d791297a68a",
   "metadata": {},
   "source": [
    "The model demonstrates strong performance after **100** epochs of training, achieving an accuracy of **87.54%** and a loss of **0.4756**. This indicates that the model has successfully learned to predict the next word in a sequence with high accuracy while minimizing the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aafcd4-c98f-4985-b4ff-36c45b8cb08c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Generating Text Using Our Trained Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c12bd-ffc1-45c3-8154-633b9d91311d",
   "metadata": {},
   "source": [
    "In this part, we test the model's ability to generate text by providing it with an initial seed phrase. The model uses this input to predict and generate the next words, one at a time, based on the patterns it learned during training. Each predicted word is added to the text, creating a longer, coherent sequence. This iterative process allows us to see how well the model understands context and its ability to generate meaningful extensions of the provided input. The result is a combination of the original seed text and the newly generated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7012e60a-2e59-4626-b9ba-23e498986a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Original text: 'if he leaves'\n",
      "Generated text: 'if he leaves room upon the'\n"
     ]
    }
   ],
   "source": [
    "# Initial seed text for generating new words\n",
    "seed_text = \"if he leaves\"\n",
    "num_words_to_generate = 3  # Number of words to generate\n",
    "original_text = seed_text\n",
    "\n",
    "# Generate the next words iteratively\n",
    "for _ in range(num_words_to_generate):\n",
    "    # Convert the current text to a sequence of tokens\n",
    "    tokenized_sequence = text_tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    tokenized_sequence = pad_sequences([tokenized_sequence], maxlen=max_seq_length - 1, padding='pre')\n",
    "    predicted_idx = np.argmax(text_generation_model.predict(tokenized_sequence), axis=-1)\n",
    "    predicted_word = \"\"\n",
    "    for word, idx in text_tokenizer.word_index.items():\n",
    "        if idx == predicted_idx:\n",
    "            predicted_word = word\n",
    "            break\n",
    "    \n",
    "    # Append the predicted word to the seed text\n",
    "    seed_text += \" \" + predicted_word\n",
    "\n",
    "print(f\"Original text: '{original_text}'\")\n",
    "print(f\"Generated text: '{seed_text}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc033e4-9cef-4cc5-ae21-86d7dff92213",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #3498db;\">Conclusion</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbf99f-45ac-4d76-a928-dbfea9b212ba",
   "metadata": {},
   "source": [
    "In this project, we successfully built and trained a text generation model using an LSTM-based neural network. Starting with raw textual data from \"The Adventures of Sherlock Holmes,\" we cleaned, tokenized, and preprocessed the text to prepare it for training. By creating n-gram sequences and padding them to a uniform length, we ensured that the model could effectively learn the contextual relationships between words.\n",
    "\n",
    "The training process demonstrated the model's strong performance, achieving an accuracy of **87.54%** and a loss of **0.4756** after **100** epochs. These metrics highlight the model's ability to accurately predict the next word in a sequence while maintaining a low error rate. Additionally, the generated text showcased its capability to extend input phrases in a meaningful and contextually relevant way.\n",
    "\n",
    "While the results are impressive, there are areas for further improvement. Using a larger and more diverse dataset, experimenting with advanced architectures like Transformer models, or implementing techniques to reduce repetitive patterns could enhance the quality of the generated text even further.\n",
    "\n",
    "Overall, this project highlights the potential of deep learning in natural language processing. It serves as a solid foundation for developing more sophisticated applications, such as chatbots, text summarization, and creative writing tools, that rely on text generation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce73a4-d95b-4610-b091-47f2e553b8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
